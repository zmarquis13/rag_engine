{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86b98d42-1451-41e9-96de-4ec149120a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  What's a pumping length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: A pumping length is a special value associated with context-free languages that is used in the context of the pumping lemma for context-free languages. It indicates a minimum length such that any string in the language that is longer than this length can be \"pumped,\" meaning it can be divided into parts in a specific way that allows certain parts to be repeated any number of times while still resulting in a string that remains in the language. The pumping length helps in proving whether certain languages are context-free or not.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  what's the vibe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: I don't know.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  What's the pumping length for the regular expression ba(bb*a)*a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: I don't know.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  Give an example of a regular expression and its pumping length\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: I don't know.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  Give an example of a regular expression\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: An example of a regular expression is (0∪1)∗, which describes the language consisting of all possible strings of 0s and 1s.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  What's the pumping length for the regular expression ba∗(bb∗)∗a?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: I don't know.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  How can I determine pumping length from a regular expression?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: I don't know.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  How can pumping length be determined?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The pumping length can be determined by analyzing the specific language in question and applying the conditions of the pumping lemma. For regular languages, the pumping length is typically a minimum value that ensures any string longer than this length can be divided into three parts (x, y, z) such that the string can be \"pumped\" (i.e., the y part can be repeated any number of times) while still remaining in the language. \n",
      "For context-free languages, the pumping length is determined similarly, but the string is divided into five parts, allowing for more complex repetitions. The exact pumping length can vary based on the structure of the language and its strings. \n",
      "In the provided context, examples are given where the minimum pumping lengths are specified for various languages, along with justifications for those lengths based on the properties of the strings in the language.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  What are some of these examples?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Here are some examples of minimum pumping lengths for various languages along with justifications:\n",
      "a. 0001∗: The minimum pumping length is 1. The string \"000\" cannot be pumped, but any string of length 1 or more can be pumped by dividing it into parts.\n",
      "b. 0∗1∗: The minimum pumping length is 2. The string \"01\" cannot be pumped, but any string of length 2 or more can be pumped.\n",
      "c. 001∪0∗1∗: The minimum pumping length is 3. The string \"001\" cannot be pumped, but any string of length 3 or more can be pumped.\n",
      "d. 0∗1+0+1∗∪10∗1: The minimum pumping length is 3. The string \"11\" cannot be pumped, but any string of length 3 or more can be pumped.\n",
      "e. (01)∗: The minimum pumping length is 2. The string \"01\" can be pumped.\n",
      "f. ε: The minimum pumping length is 1. The empty string cannot be pumped.\n",
      "g. 1∗01∗01∗: The minimum pumping length is 3. The string \"101\" can be pumped.\n",
      "h. 10(11∗0)∗0: The minimum pumping length is 3. The string \"100\" can be pumped.\n",
      "i. 1011: The minimum pumping length is 4. The string \"1011\" cannot be pumped.\n",
      "j. Σ∗: The minimum pumping length is 1. Any string can be pumped.\n",
      "These examples illustrate the minimum pumping lengths for different languages based on their structure and the conditions of the pumping lemma.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.schema import messages_from_dict, messages_to_dict\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "import markdown2\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def markdown_to_text(markdown_content):\n",
    "    # Convert Markdown to HTML\n",
    "    html_content = markdown2.markdown(markdown_content)\n",
    "    \n",
    "    # Parse HTML and extract plain text\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#create a chromadb (vectorized database for RAG) from a given directory of pdf files\n",
    "def create_db_from_pdf_directory(pdf_directory, db_directory):\n",
    "    # initialize an empty list to store all documents\n",
    "    all_documents = []\n",
    "    \n",
    "    # iterate through all files in the directory\n",
    "    for filename in os.listdir(pdf_directory):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_directory, filename)\n",
    "            #print(f\"Processing {filename}...\")\n",
    "            \n",
    "            # load pdf\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # add documents to the list\n",
    "            all_documents.extend(documents)\n",
    "    \n",
    "    # split text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    texts = text_splitter.split_documents(all_documents)\n",
    "    \n",
    "    # vector embeddings instance\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    # create chromadb\n",
    "    db = Chroma.from_documents(texts, embeddings, persist_directory=db_directory)\n",
    "    \n",
    "    print(f\"Database created successfully at {db_directory}\")\n",
    "    return db\n",
    "\n",
    "\n",
    "#specify source and database and create database with it\n",
    "pdf_directory = \"pdfsnew_\"\n",
    "\n",
    "db_directory = \"chromadb\"\n",
    "\n",
    "if not os.path.exists(db_directory):\n",
    "    #print(\"Creating new Chroma database...\")\n",
    "    db = create_db_from_pdf_directory(pdf_directory, db_directory)\n",
    "else:\n",
    "    #print(\"Loading existing Chroma database...\")\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    db = Chroma(embedding_function=embeddings)\n",
    "    #print(\"Database loaded\")\n",
    "\n",
    "\n",
    "def query_db(db, query):\n",
    "    # Create a retriever from the database\n",
    "    retriever = db.as_retriever()\n",
    "    \n",
    "    # Create a ChatOpenAI model\n",
    "    chat = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    # Add memory to keep track of conversation history\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "    # Create a Conversational Retrieval Chain with memory\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(chat, retriever=retriever, memory=memory)\n",
    "    \n",
    "    # Run the query \n",
    "    result = qa_chain({\"memory\": memory, \"question\": query})\n",
    "    \n",
    "    return result['answer']\n",
    "\n",
    "def digest_new_pdfs():\n",
    "    new_pdf_dir = 'new_pdfs'\n",
    "    used_pdf_dir = 'used_pdfs'\n",
    "\n",
    "    added_documents = []\n",
    "\n",
    "    if os.listdir(new_pdf_dir):\n",
    "\n",
    "        print('processing new content')\n",
    "        for file in os.listdir(new_pdf_dir):\n",
    "            if file.endswith(\".pdf\"):\n",
    "                # load pdf\n",
    "                pdf_path = os.path.join(new_pdf_dir, file)\n",
    "                loader = PyPDFLoader(pdf_path)\n",
    "                documents = loader.load()\n",
    "                \n",
    "                # add documents to the list\n",
    "                added_documents.extend(documents)\n",
    "                \n",
    "                source_file = os.path.join(new_pdf_dir, file)\n",
    "                destination_file = os.path.join(used_pdf_dir, file)\n",
    "                shutil.move(source_file, destination_file)\n",
    "    \n",
    "        # split text into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        texts = text_splitter.split_documents(added_documents)\n",
    "        \n",
    "        # vector embeddings instance\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "        # add the embeddings to the existing ChromaDB instance\n",
    "        db.add_documents(documents=texts, embeddings=embeddings)\n",
    "\n",
    "        print('processing complete')\n",
    "\n",
    "# First digest new pdfs\n",
    "digest_new_pdfs()\n",
    "\n",
    "# Create a retriever from the database\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# Create a ChatOpenAI model\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Add memory to keep track of conversation history\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Create a Conversational Retrieval Chain with memory\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(chat, retriever=retriever, memory=memory)\n",
    "\n",
    "\n",
    "# Interactive loop\n",
    "while True:\n",
    "    query = input(\"\\nAsk a question (or type 'exit' to quit): \")\n",
    "    if query.lower() == 'exit':\n",
    "        break\n",
    "    elif query.lower() == 'add':\n",
    "        # Add new PDFs to ChromaDB\n",
    "        new_pdf_directory = input(\"Enter the path to the directory with new PDFs: \")\n",
    "        # Function to add new PDFs would go here\n",
    "        # add_new_pdfs_to_chromadb(new_pdf_directory, db)\n",
    "        print(\"New PDFs added to ChromaDB.\")\n",
    "    else:\n",
    "        #response = query_db(db, query)\n",
    "\n",
    "        # Run the query \n",
    "        result = qa_chain({\"question\": query})\n",
    "        print(f\"Response: {markdown_to_text(result['answer'])}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563bfb03-b06a-4fb2-b11d-7954e8438f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
