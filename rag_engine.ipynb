{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86b98d42-1451-41e9-96de-4ec149120a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing new content\n",
      "processing complete\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  What's the pumping lemma?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The pumping lemma for regular languages states that if A is a regular language, then there is a number p (the pumping length) such that if s is any string in A of length at least p, then s can be divided into three pieces, s = xyz, satisfying the following conditions:\n",
      "\n",
      "For each i ≥ 0, xy^iz ∈ A.\n",
      "|y| > 0 (the length of y is greater than 0).\n",
      "|xy| ≤ p (the length of the concatenation of x and y is at most p).\n",
      "\n",
      "This lemma is used to prove that certain languages are not regular by showing that they do not have this property.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  what's an example of a non-regular language?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: An example of a non-regular language is D = {1^n 2 | n ≥ 0}, which contains all strings of 1s whose length is a perfect square.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Ask a question (or type 'exit' to quit):  exit\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.schema import messages_from_dict, messages_to_dict\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "import markdown2\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def markdown_to_text(markdown_content):\n",
    "    # Convert Markdown to HTML\n",
    "    html_content = markdown2.markdown(markdown_content)\n",
    "    \n",
    "    # Parse HTML and extract plain text\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#create a chromadb (vectorized database for RAG) from a given directory of pdf files\n",
    "def create_db_from_pdf_directory(pdf_directory, db_directory):\n",
    "    # initialize an empty list to store all documents\n",
    "    all_documents = []\n",
    "    \n",
    "    # iterate through all files in the directory\n",
    "    for filename in os.listdir(pdf_directory):\n",
    "        if filename.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_directory, filename)\n",
    "            #print(f\"Processing {filename}...\")\n",
    "            \n",
    "            # load pdf\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # add documents to the list\n",
    "            all_documents.extend(documents)\n",
    "    \n",
    "    # split text into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    texts = text_splitter.split_documents(all_documents)\n",
    "    \n",
    "    # vector embeddings instance\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    # create chromadb\n",
    "    db = Chroma.from_documents(texts, embeddings, persist_directory=db_directory)\n",
    "    \n",
    "    print(f\"Database created successfully at {db_directory}\")\n",
    "    return db\n",
    "\n",
    "\n",
    "#specify source and database and create database with it\n",
    "pdf_directory = \"pdfsnew_\"\n",
    "\n",
    "db_directory = \"chromadb\"\n",
    "\n",
    "if not os.path.exists(db_directory):\n",
    "    #print(\"Creating new Chroma database...\")\n",
    "    db = create_db_from_pdf_directory(pdf_directory, db_directory)\n",
    "else:\n",
    "    #print(\"Loading existing Chroma database...\")\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    db = Chroma(embedding_function=embeddings)\n",
    "    #print(\"Database loaded\")\n",
    "\n",
    "\n",
    "def query_db(db, query):\n",
    "    # Create a retriever from the database\n",
    "    retriever = db.as_retriever()\n",
    "    \n",
    "    # Create a ChatOpenAI model\n",
    "    chat = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    # Add memory to keep track of conversation history\n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "    # Create a Conversational Retrieval Chain with memory\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(chat, retriever=retriever, memory=memory)\n",
    "    \n",
    "    # Run the query \n",
    "    result = qa_chain({\"memory\": memory, \"question\": query})\n",
    "    \n",
    "    return result['answer']\n",
    "\n",
    "def digest_new_pdfs():\n",
    "    new_pdf_dir = 'new_pdfs'\n",
    "    used_pdf_dir = 'used_pdfs'\n",
    "\n",
    "    added_documents = []\n",
    "\n",
    "    if os.listdir(new_pdf_dir):\n",
    "\n",
    "        print('processing new content')\n",
    "        for file in os.listdir(new_pdf_dir):\n",
    "            if file.endswith(\".pdf\"):\n",
    "                # load pdf\n",
    "                pdf_path = os.path.join(new_pdf_dir, file)\n",
    "                loader = PyPDFLoader(pdf_path)\n",
    "                documents = loader.load()\n",
    "                \n",
    "                # add documents to the list\n",
    "                added_documents.extend(documents)\n",
    "                \n",
    "                source_file = os.path.join(new_pdf_dir, file)\n",
    "                destination_file = os.path.join(used_pdf_dir, file)\n",
    "                shutil.move(source_file, destination_file)\n",
    "    \n",
    "        # split text into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "        texts = text_splitter.split_documents(added_documents)\n",
    "        \n",
    "        # vector embeddings instance\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "        # add the embeddings to the existing ChromaDB instance\n",
    "        db.add_documents(documents=texts, embeddings=embeddings)\n",
    "\n",
    "        print('processing complete')\n",
    "\n",
    "# First digest new pdfs\n",
    "digest_new_pdfs()\n",
    "\n",
    "# Create a retriever from the database\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# Create a ChatOpenAI model\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Add memory to keep track of conversation history\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Create a Conversational Retrieval Chain with memory\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(chat, retriever=retriever, memory=memory)\n",
    "\n",
    "\n",
    "# Interactive loop\n",
    "while True:\n",
    "    query = input(\"\\nAsk a question (or type 'exit' to quit): \")\n",
    "    if query.lower() == 'exit':\n",
    "        break\n",
    "    elif query.lower() == 'add':\n",
    "        # Add new PDFs to ChromaDB\n",
    "        new_pdf_directory = input(\"Enter the path to the directory with new PDFs: \")\n",
    "        # Function to add new PDFs would go here\n",
    "        # add_new_pdfs_to_chromadb(new_pdf_directory, db)\n",
    "        print(\"New PDFs added to ChromaDB.\")\n",
    "    else:\n",
    "        #response = query_db(db, query)\n",
    "\n",
    "        # Run the query \n",
    "        result = qa_chain({\"question\": query})\n",
    "        print(f\"Response: {markdown_to_text(result['answer'])}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
